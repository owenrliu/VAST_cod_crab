---
title: "VAST Cod and Crab"
author: "Owen Liu"
date: "1/21/2020"
output: html_document
---

## Purpose

This script runs a VAST model for Pacific cod *Gadus macrocephalus* and snow crab *Chionoecetes opilio* to calculate spatio-temporal estimates of distribution.

## Setup and Data

```{r}
library(TMB)
library(VAST)
library(tidyverse)
library(here)
library(magrittr)
map <- maps::map

# figure theme
plot_theme <-   theme_minimal()+
  theme(text=element_text(family="sans",size=12,color="black"),
        legend.text = element_text(size=14),
        axis.title=element_text(family="sans",size=14,color="black"),
        axis.text=element_text(family="sans",size=8,color="black"),
        panel.grid.major = element_line(color="gray50",linetype=3))
theme_set(plot_theme)

fp = here::here('data','VAST output')

model_directory <- here::here('VAST models')

####
Version = get_latest_version( package="VAST" )

```

## Cod and Crab data

The organization of the cod and crab data starting from raw versions was done with scripts available in `data/scripts/`.

```{r}
## Cod and crab data
opi_dat_long <- read_rds(here::here('data','processed','longform_opilio.rds'))
cod_dat <- read_rds(here::here('data','processed','cod_dat_clean.rds'))
```

### Organize Crab Data

```{r}
# size frequency of immature crabs
opi_imm_n <- opi_dat_long %>% filter(maturity=="Immature",units=="numbers") %>% 
  group_by(size) %>% 
  summarise(totn=sum(value)) %>% 
  ungroup()
opi_imm_n %>% ggplot(aes(size,totn))+geom_bar(stat='identity')+labs(x="Carapace Width",y="Total Number",title="Immature Snow Crab Size Frequency")

# filter for immature or mature female crabs, summarise total numbers by station/year
# In cod stomachs, 95% of crabs range between 8 and 57mm carapace width. So we will also use this as a cutoff
dat_opilio <- opi_dat_long %>% 
  mutate(spp=case_when(
    maturity=="Immature"&size<58 ~ "Opilio immature",
    maturity=="Mature" & sex=="Female" ~ "Opilio spawner",
    TRUE ~ NA_character_
  )) %>% 
  filter(!is.na(spp),units=="numbers") %>% 
  group_by(spp,year,lon,lat,area_km2) %>% 
  summarise(abun=round(sum(value,na.rm=T))) %>% 
  ungroup() %>% 
  mutate(vessel=0)
```

### Organize Cod Data

```{r}
# For cod- split by 3 size classes (0-200mm FL, 200-800mm, >800mm) following Burgos et al. (2013)
# for cod sizes expected to not eat crab, eat crab often, and eat crab rarely, respectively
dat_gadus <- cod_dat %>% 
  rename(lon=midlon,lat=midlat) %>% 
  mutate(size_class=case_when(
    length<=200 ~ "small cod",
    length>200 & length<=800 ~ "medium cod",
    length>800 ~ "large cod"
  )) %>% 
  group_by(size_class,year,lon,lat) %>% 
  summarise(abun=sum(frequency,na.rm=T)) %>% 
  ungroup() %>% 
  # add area swept for reference
  mutate(spp=size_class,vessel=0,area_km2=0.01) %>% 
  select(spp,year,lon,lat,area_km2,abun,vessel)
```

### Combine

```{r}
# combine and add missing zeros for missing tows
dat_combined <- bind_rows(dat_opilio,dat_gadus) %>%
  mutate(spp=factor(spp,levels=c("Opilio immature","Opilio spawner","small cod","medium cod","large cod"))) %>% 
  filter(!is.na(lat),!is.na(lon),year<2018) %>% 
  # do we fill in zeroes? for all tow/spp combinations that were previously missing
  complete(spp,nesting(year,lat,lon),fill=list(abun=0,area_km2=0.01,vessel=0)) %>%
  ungroup() %>%
  # complete(spp,nesting(year,lat,lon),fill=list(area_km2=0.01,vessel=0))
  select(spp,year,lon,lat,area_km2,abun,vessel) %>% 
  rename(Lat=lat,Lon=lon)

# data check- number of zeroes and NAs
zeroes_check <- dat_combined %>% 
  group_by(year,spp) %>% 
  summarise(num_zeroes=sum(abun==0),num_NA=sum(is.na(abun)),total_n=n(),perc=num_zeroes/total_n) %>% 
  arrange(spp,year)
```

## Set Up VAST

```{r}
# make the extrapolation grid, building an object used to determine areas to extrapolate densities to when calculating indices
# species 
Region = "Eastern_Bering_Sea"
Species_set = c("Opilio immature","Opilio spawner","small cod","medium cod","large cod")

dat <- dat_combined %>% filter(spp %in% Species_set)

strata.limits <- data.frame(STRATA = "All_areas")

Extrapolation_List = make_extrapolation_info(Region = Region,strata.limits = strata.limits)
write_rds(Extrapolation_List,here::here('data','VAST output',"Extrapolation_List.rds"))

# Stochastic partial differential equation (SPDE) with geometric anisotropy
Method <- "Mesh"
Aniso <- 1
grid_size_km=25
n_x <- 300

# generate the information used for conducting spatio-temporal parameter estimation, bundled in list `Spatial_List`
Spatial_List = make_spatial_info(grid_size_km=grid_size_km, 
                                 n_x=n_x,
                                 Method=Method,
                                 Lon_i=dat[,'Lon'],
                                 Lat_i=dat[,'Lat'],
                                 LON_intensity=Extrapolation_List$Data_Extrap[which(Extrapolation_List$Data_Extrap[,'Include']==TRUE),'Lon'],
                                 LAT_intensity=Extrapolation_List$Data_Extrap[which(Extrapolation_List$Data_Extrap[,'Include']==TRUE),'Lat'],
                                 Extrapolation_List=Extrapolation_List, 
                                 DirPath=here::here('data','VAST output'), 
                                 Save_Results=TRUE)

write_rds(Spatial_List,here::here('data','VAST output',"Spatial_List.rds"))

# Add the knots to the the data
dat <- dat %>% mutate(knot_i=Spatial_List$knot_i)

# Spatial settings

# whether to include spatial (omega) and s-t (epsilon) variation
# for two linear predictors- 1. encounter probability, and 2. positive catch rate
# for a univariate model, these are 0 ("turned off") or 1
# for a multivariate model, can be any whole number 0:C, where C is the number of categories
# indicating the number of factors to estimate
FieldConfig = c(Omega1 = 3, Epsilon1 = 3, Omega2 = 3,
                Epsilon2 = 3)
# is there temporal correlation in the intercepts (Beta) or s-t variation (Epsilon)?
# 0: each year as fixed effect; 
# 1: each year as random following IID distribution; 
# 2: each year as random following a random walk; 
# 3: constant among years as fixed effect; 
# 4: each year as random following AR1 process
RhoConfig = c(Beta1 = 3, Beta2 = 3, Epsilon1 = 0, Epsilon2 = 0)

# is there overdispersion? often attributable to 'vessel effects'
# 0 means no overdispersion
OverdispersionConfig = c("Eta1"=0, "Eta2"=0)

# Options to estimate interactions

# Options to estimate interactions, where 
# first slot selects method for forming interaction matrix
# second indicates rank
# third indicates whether to incorporate effect of F_ct, 
# fourth indicates whether to add a new "t=0" year (while incrementing all t_i inputs) which represents B0
# Method = 2 means Real-eigenvalues
VamConfig	<- c("Method"=0,"Rank"=0, "Timing" =0)

# what distributions and link functions to use?
# first is the distribution for positive catch rates, 
# second is the functional form for encounter probabilities,
# we choose a normal distribution for positive catch rates and a conventional delta-model for enc prob
# 
ObsModel = c(2, 1)

#outputs we want
Options = c(SD_site_density = 0, SD_site_logdensity = 0,
            Calculate_Range = 1, Calculate_evenness = 0, Calculate_effective_area = 1,
            Calculate_Cov_SE = 0, Calculate_Synchrony = 0,
            Calculate_Coherence = 0)

# save settings and data in a list

Record = list(Version = Version, 
              Method = Method,
              n_x = n_x, 
              Aniso = Aniso,
              FieldConfig = FieldConfig, 
              RhoConfig = RhoConfig,
              OverdispersionConfig = OverdispersionConfig, 
              VamConfig=VamConfig, 
              ObsModel = ObsModel,
              Region = Region,
              Species_set = Species_set, 
              strata.limits = strata.limits,
              Options=Options)
save(Record, file = here::here('data','VAST output', "Record.RData"))
capture.output(Record, file = here::here('data','VAST output', "Record.txt"))
```

## Environmental Covariates

We import and organize the environmental density covariates.

```{r}
# Finally, we need the density covariates (temperature and depth)
# We use temperature and depth data interpolated in another script
library(RANN)
nbt.interpolated <- read_rds(here::here('data','processed','nbt_interpolated.rds')) %>% 
  #normalize to zero mean and unit variance
  mutate(temp_norm=(temp-mean(temp))/sd(temp)) %>% 
  select(-temp)

depth.interpolated <- read_rds(here::here('data','processed','depth_interpolated.rds')) %>% select(-year) %>% 
  #normalize to zero mean and unit variance
  mutate(depth_norm=(depth-mean(depth))/sd(depth)) %>% 
  select(-depth)


# Find nearest neighbors for environmental covariates
# change for VAST 8_0_0 : no need to make array of density data
# instead we provide lat/lon/covariates, plus a formula
# formula includes quadratic terms for both covariates

# For each year of sampling data, find the nearest neighbor in temp/depth data
# we need the locations of data in UTM coordinates because that's what the covariate data contain
loc_i <- Spatial_List[['loc_i']] %>% as_tibble() %>% set_names(c("E_km","N_km"))
dat_utm <- dat %>% bind_cols(loc_i)
loc_query <- loc_i %>% select(E_km,N_km)
  
# locations of interpolated temperature and depth info (temp and depth have the same interpolated points)
loc_covars <- nbt.interpolated %>% distinct(x,y)

# find nearest neighbors
which_nn <- nn2(data=loc_covars,query=loc_query,k=1)$nn.idx[,1]

# add observation numbers to covariate data to match to nearest neighbor calculation
nbt.interpolated %<>% group_by(year) %>% mutate(obs=row_number()) %>% ungroup() %>% select(year,obs,temp_norm)
depth.interpolated %<>% ungroup() %>%  mutate(obs=row_number()) %>% select(obs,depth_norm)

# produce data frame of covariate data
covars <- dat_utm %>% mutate(nn_covar=which_nn) %>% 
  # join temperature data based on year and nearest-neighbor observation
  left_join(nbt.interpolated,by=c('year','nn_covar'='obs')) %>% 
  left_join(depth.interpolated,by=c('nn_covar'='obs')) %>% 
  select(Lat,Lon,year,temp_norm,depth_norm) %>% 
  rename(Year=year)

formula = ~temp_norm + depth_norm +I(temp_norm^2)+I(depth_norm^2)

## DEPRECATED: OLD X_xtp version
# make_density_covariates <- function(type="loc_x") {
#   # locations of knots from Spatial_List object
#   loc_query <- Spatial_List[[type]]
#   # years
#   yrs <- seq(min(dat$year),max(dat$year))
#   # locations of interpolated temperature and depth info
#   loc_covars <- nbt.interpolated %>% distinct(x,y)
#   # nearest neighbors (knots and interpolated covariates)
#   which_nn <- nn2(data=loc_covars,query=loc_query,k=1)$nn.idx[,1]
#   # for each knot in each year, find nearest neighbor from the interpolated datasets
#   X_xtp <- array(data=NA,dim=c(nrow(loc_query),length(yrs),4))
#   # fill in covariates for each knot in each year
#   # depth is constant across years
#   for(j in 1:length(yrs)) {
#     yr_temp <- nbt.interpolated %>% filter(year==yrs[j])
#     X_xtp[,j,1] <- yr_temp$temp[which_nn]
#     X_xtp[,j,2] <- depth.interpolated$depth[which_nn]
#   }
#   return(X_xtp)
# }
# 
# X_gtp <- make_density_covariates(type="loc_x")
# X_itp <- make_density_covariates(type="loc_i")
```

## Build and Run VAST Model

```{r}
# in order to estimate params, build a list of data-inputs used for param estimation
TmbData = make_data("Version"=Version, 
                    "FieldConfig"=FieldConfig,
                    "OverdispersionConfig"=OverdispersionConfig, 
                    "RhoConfig"=RhoConfig, 
                    "VamConfig" = VamConfig,
                    "ObsModel"=ObsModel,
                    "spatial_list"=Spatial_List,
                    "c_iz"=as.numeric(dat$spp)-1,
                    "b_i"=dat$abun, 
                    "a_i"=dat$area_km2, 
                    "v_i"=as.numeric(dat$vessel)-1, 
                    "s_i"=dat$knot_i-1, 
                    "t_iz"=dat$year,
                    "a_xl"=Spatial_List$a_xl,
                    "covariate_data"=covars,
                    "formula"= formula,
                    "MeshList"=Spatial_List$MeshList,
                    "GridList"=Spatial_List$GridList,
                    "Method"=Spatial_List$Method,
                    "Aniso"=Aniso,
                    "Options"=Options)

## Build TMB model object
TmbList = make_model("build_model"=TRUE,
                     "TmbData"=TmbData, 
                     "RunDir"=model_directory, 
                     "Version"=Version, 
                     "RhoConfig"=RhoConfig, 
                     "loc_x"=Spatial_List$loc_x, 
                     "Method"=Method)
Map = TmbList$Map
Parameters = TmbList$Parameters
```

Run parameter estimation

```{r}
# Optimize
Obj = TmbList[["Obj"]]
Obj$fn( Obj$par )
Obj$gr( Obj$par )

# Optimize
# Bias Correct?
BiasCorr= TRUE
Opt = TMBhelper::fit_tmb( obj=Obj, lower=TmbList[["Lower"]], upper=TmbList[["Upper"]], savedir=fp, getsd=TRUE, 
                           bias.correct=BiasCorr, newtonsteps=1, 
                           bias.correct.control=list(sd=FALSE, split=NULL, nsplit=1, vars_to_correct=c("Index_cyl","effective_area_cyl","mean_Z_cym")))
SDr <- sdreport(Obj)
Opt$time_for_run
Report = Obj$report()
Save = list("Opt"=Opt, "Report"=Report, SDReport=SDr, "ParHat"=Obj$env$parList(Opt$par), "Data"=dat, "Map"=Map)
save(Save, file=here::here('data','VAST output',"Save.RData"))
if("opt" %in% names(Opt)) capture.output( Opt$opt, file=here::here('data','VAST output',"parameter_estimates.txt"))
```

## Explore Model Outputs

### Diagnostic plots
```{r}
# if not re-running, load
load(here::here('data','VAST output',"Record.Rdata"))
load(here::here('data','VAST output',"Save.RData"))
Spatial_List <- read_rds(here::here('data','VAST output',"Spatial_List.rds"))
load(here::here('data','VAST output',"parameter_estimates.Rdata"))
dat <- Save$Data
list2env(Record,envir = environment())

names(dat) <- c("spp","Year","Lon","Lat","area_km2", "Catch_KG","vessel","knot_i")
source(here::here('data','scripts','output__helper_fxns.R'))
# diagnostic plots
# plot_data(Extrapolation_List=Extrapolation_List, Spatial_List=Spatial_List, Data_Geostat=dat, PlotDir=fp )

# convergence
pander::pandoc.table(Save$Opt$diagnostics[,c('Param','Lower','MLE','Upper','final_gradient')] ) 

## Check encounter probabilities
# Check whether observed encounter frequencies for either low or high probability samples 
# are within the 95% predictive interval for predicted encounter probability
Enc_prob = plot_encounter_diagnostic( Report=Save$Report, Data_Geostat=dat, DirName=fp)

# Check positive catch-rate
#nWe can visualize fit to residuals of catch-rates given encounters using a Q-Q plot.  
# A good Q-Q plot will have residuals along the one-to-one line.  

Q = plot_quantile_diagnostic( TmbData=TmbData, Report=Report, FileName_PP="Posterior_Predictive",
                              FileName_Phist="Posterior_Predictive-Histogram", 
                              FileName_QQ="Q-Q_plot", FileName_Qhist="Q-Q_hist", DateFile=fp )

save(Q,file=paste0(fp,"quantile_diag.Rdata"))

## Plotting residuals on a map
# Get region-specific settings for plots
MapDetails_List = make_map_info( "Region"=Region,spatial_list = Spatial_List, "NN_Extrap"=Spatial_List$PolygonList$NN_Extrap, "Extrapolation_List"=Extrapolation_List )
# Decide which years to plot                                                   
Year_Set = seq(min(dat$Year),max(dat$Year))
Years2Include = which( Year_Set %in% sort(unique(dat$Year)))

# Plot Pearson residuals.  
# If there are visible patterns (areas with consistently positive or negative residuals accross or within years) 
# then this is an indication of the model "overshrinking" results towards the intercept, and model results should then be treated with caution.  
TmbData$n_x <- 300
res <- plot_residuals(Lat_i=dat[,'Lat'], Lon_i=dat[,'Lon'], spatial_list=Spatial_List,TmbData=TmbData, Report=Save$Report, Q=Q, 
               savdir=fp, extrapolation_list = Extrapolation_List, mar=c(0,0,2,0), oma=c(3.5,3.5,0,0), cex=1.8)

## Direction of "geometric anisotropy"

# We can visualize which direction has faster or slower decorrelation (termed "geometric anisotropy")
plot_anisotropy( FileName=paste0(fp,"Aniso.png"), Report=Report, TmbData=TmbData )

```

### Model Outputs

```{r}
#### View Model Outputs ####

## Plot spatial and spatio-temporal covariance

# Spatial and spatio-temporal covariance among species in encounter probability and positive catch rates 
# (depending upon what is turned on via `FieldConfig`)
# Cor_List = summarize_covariance( Report=Report, ParHat=Obj$env$parList(), Data=TmbData, 
#                                  SD=SDr, plot_cor=TRUE,figname = "Cor", category_names=levels(dat$spp), 
#                                  plotdir=fp, mgp=c(2,0.5,0), tck=-0.02, oma=c(0,5,2,2) )
# Cov_List = summarize_covariance( Report=Report, ParHat=Obj$env$parList(), Data=TmbData, 
#                                  SD=SDr, plot_cor=FALSE,figname = "Cov", category_names=levels(dat$spp), 
#                                  plotdir=fp, mgp=c(2,0.5,0), tck=-0.02, oma=c(0,5,2,2) )

## Density surface for each year
# predicted density, but other options are obtained via other integers passed to `plot_set` as described in `?plot_maps`
plot_density(Region,Spatial_List,Report,Extrapolation_List,dat,fp,saveplots = T)
# Dens_xt = plot_maps(plot_set=c(3), MappingDetails=MapDetails_List[["MappingDetails"]], Report=Report, 
#                     Sdreport=Opt$SD, PlotDF=MapDetails_List[["PlotDF"]], MapSizeRatio=MapDetails_List[["MapSizeRatio"]], 
#                     Xlim=MapDetails_List[["Xlim"]], Ylim=MapDetails_List[["Ylim"]], FileName=fp, Year_Set=Year_Set, 
#                     Years2Include=Years2Include, Rotate=MapDetails_List[["Rotate"]], Cex=MapDetails_List[["Cex"]], category_names = levels(dat$spp),
#                     Legend=MapDetails_List[["Legend"]], zone=MapDetails_List[["Zone"]], mar=c(0,0,2,0), oma=c(3.5,3.5,0,0),
#                     cex=1.8, plot_legend_fig=FALSE)

## Index of abundance
# The index of abundance is generally most useful for stock assessment models.
Index = plot_biomass_index( DirName=fp, TmbData=TmbData, Sdreport=SDr, Year_Set=Year_Set, 
                            category_names=levels(dat$spp),Years2Include=Years2Include, use_biascorr=TRUE )
pander::pandoc.table( Index$Table[,c("Year","Fleet","Estimate_metric_tons","SD_log","SD_mt")] ) 

# Range expansion/contraction
range_index <- plot_range_index(Report=Report, TmbData=TmbData, Sdreport=SDr, Znames=colnames(TmbData$Z_xm), PlotDir=fp, 
                 category_names = levels(dat$spp),Year_Set=Year_Set)


## Plot factors
# Finally, we can inspect the factor-decomposition for community-level patterns.  
# This generates many plots
factors <- Plot_factors( Report=Save$Report, ParHat=Save$ParHat, Data=TmbData, SD=SDr, mapdetails_list=MapDetails_List, 
                         Year_Set=Year_Set, category_names=levels(dat$spp), plotdir=fp )
fct_loadings <- plot_fct_loadings(factors,dat,rotated = TRUE,fp)

outs <- list(factors=factors,fct_loadings=fct_loadings,res=res,Index=Index,range_index=range_index)
save(outs,file=paste0(fp,"derived_quantities.Rdata"))
```

### Correlations

```{r}

```

